{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3accdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374933fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    # U-net모델 만들기\n",
    "    ## tools\n",
    "    conv_filters = [256, 128, 64, 32, 16, 8]\n",
    "    cont_factory = partial(\n",
    "        keras.layers.Conv2D, kernel_size=(3,3), strides=1, padding=\"same\"\n",
    "    )\n",
    "    cont_activation = keras.layers.ELU()\n",
    "\n",
    "    expan_factory = partial(\n",
    "        keras.layers.Conv2DTranspose,\n",
    "        kernel_size=(3,3), strides=1, padding=\"same\"\n",
    "    )\n",
    "    expan_activation = keras.layers.LeakyReLU(0.2)\n",
    "\n",
    "    ## Input\n",
    "    inputs = keras.Input((None,n_bins,1))\n",
    "    ## Contracting path\n",
    "    ## 1\n",
    "    conv1 = cont_factory(conv_filters[0])(inputs)\n",
    "    batch1 = keras.layers.BatchNormalization(axis=-1)(conv1)\n",
    "    rel1 = cont_activation(batch1)\n",
    "    ## 2\n",
    "    conv2 = cont_factory(conv_filters[1])(rel1)\n",
    "    batch2 = keras.layers.BatchNormalization(axis=-1)(conv2)\n",
    "    rel2 = cont_activation(batch2)\n",
    "    ## 3\n",
    "    conv3 = cont_factory(conv_filters[2])(rel2)\n",
    "    batch3 = keras.layers.BatchNormalization(axis=-1)(conv3)\n",
    "    rel3 = cont_activation(batch3)\n",
    "    ## 4\n",
    "    conv4 = cont_factory(conv_filters[3])(rel3)\n",
    "    batch4 = keras.layers.BatchNormalization(axis=-1)(conv4)\n",
    "    rel4 = cont_activation(batch4)\n",
    "    ## 5\n",
    "    conv5 = cont_factory(conv_filters[4])(rel4)\n",
    "    batch5 = keras.layers.BatchNormalization(axis=-1)(conv5)\n",
    "    rel5 = cont_activation(batch5)\n",
    "    ## 6\n",
    "    conv6 = cont_factory(conv_filters[5])(rel5)\n",
    "\n",
    "    ## Expansive path\n",
    "    ## 6\n",
    "    up1 = expan_factory(conv_filters[4])(conv6)\n",
    "    up1 = expan_activation(up1)\n",
    "    up_batch1 = keras.layers.BatchNormalization(axis=-1)(up1)\n",
    "    drop1 = keras.layers.Dropout(0.5)(up_batch1)\n",
    "    merge1 = keras.layers.Concatenate(axis=-1)([conv5,drop1])\n",
    "    ## 5\n",
    "    up2 = expan_factory(conv_filters[3])(merge1)\n",
    "    up2 = expan_activation(up2)\n",
    "    up_batch2 = keras.layers.BatchNormalization(axis=-1)(up2)\n",
    "    drop2 = keras.layers.Dropout(0.5)(up_batch2)\n",
    "    merge2 = keras.layers.Concatenate(axis=-1)([conv4,drop2])\n",
    "    ## 4\n",
    "    up3 = expan_factory(conv_filters[2])(merge2)\n",
    "    up3 = expan_activation(up3)\n",
    "    up_batch3 = keras.layers.BatchNormalization(axis=-1)(up3)\n",
    "    drop3 = keras.layers.Dropout(0.5)(up_batch3)\n",
    "    merge3 = keras.layers.Concatenate(axis=-1)([conv3,drop3])\n",
    "    ## 3\n",
    "    up4 = expan_factory(conv_filters[1])(merge3)\n",
    "    up4 = expan_activation(up4)\n",
    "    up_batch4 = keras.layers.BatchNormalization(axis=-1)(up4)\n",
    "    drop4 = keras.layers.Dropout(0.5)(up_batch4)\n",
    "    merge4 = keras.layers.Concatenate(axis=-1)([conv2,drop4])\n",
    "    ## 2\n",
    "    up5 = expan_factory(conv_filters[0])(merge4)\n",
    "    up5 = expan_activation(up5)\n",
    "    up_batch5 = keras.layers.BatchNormalization(axis=-1)(up5)\n",
    "    drop5 = keras.layers.Dropout(0.5)(up_batch5)\n",
    "    merge5 = keras.layers.Concatenate(axis=-1)([conv1,drop5])\n",
    "    ## 1\n",
    "    up6 = expan_factory(1)(merge5)\n",
    "    up6 = expan_activation(up6)\n",
    "    up_batch6 = keras.layers.BatchNormalization(axis=-1)(up6)\n",
    "    ## output\n",
    "    outputs = keras.layers.Conv2D(1, (4,4),\n",
    "                                  dilation_rate=(2,2),\n",
    "                                  activation=\"sigmoid\",\n",
    "                                  padding=\"same\"\n",
    "                                 )(up_batch6)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_u_net()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimazer = tf.keras.optimizers.Adadelta( # 지속적으로 학습률이 줄어듬\n",
    "    learning_rate=0.1, # 초기 학습률\n",
    ")\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer = optimazer,\n",
    "              metrics = \"accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MA",
   "language": "python",
   "name": "ma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
