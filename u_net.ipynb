{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.compat import v1\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cqt.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\suo24\\Desktop\\Projects\\AI_Training\\music_analysis\\u_net.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/suo24/Desktop/Projects/AI_Training/music_analysis/u_net.ipynb#ch0000001?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mcqt.npz\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suo24/Desktop/Projects/AI_Training/music_analysis/u_net.ipynb#ch0000001?line=1'>2</a>\u001b[0m train \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mamplitude_to_db(data[\u001b[39m'\u001b[39m\u001b[39mspec\u001b[39m\u001b[39m'\u001b[39m], ref\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmax)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m168\u001b[39m,\u001b[39m87\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39m# cqt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/suo24/Desktop/Projects/AI_Training/music_analysis/u_net.ipynb#ch0000001?line=2'>3</a>\u001b[0m train \u001b[39m=\u001b[39m (train\u001b[39m+\u001b[39m\u001b[39m80\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m80\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MA\\lib\\site-packages\\numpy\\lib\\npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/suo24/anaconda3/envs/MA/lib/site-packages/numpy/lib/npyio.py?line=414'>415</a>\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/suo24/anaconda3/envs/MA/lib/site-packages/numpy/lib/npyio.py?line=415'>416</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/suo24/anaconda3/envs/MA/lib/site-packages/numpy/lib/npyio.py?line=416'>417</a>\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    <a href='file:///c%3A/Users/suo24/anaconda3/envs/MA/lib/site-packages/numpy/lib/npyio.py?line=417'>418</a>\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/suo24/anaconda3/envs/MA/lib/site-packages/numpy/lib/npyio.py?line=419'>420</a>\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cqt.npz'"
     ]
    }
   ],
   "source": [
    "data = np.load('cqt.npz')\n",
    "train = librosa.amplitude_to_db(data['spec'], ref=np.max).reshape(-1, 168,87,1) # cqt\n",
    "train = (train+80)/80\n",
    "instr_target = data['instr'][:,0] # instr\n",
    "note_target = data['instr'][:,1] # note\n",
    "print(train.shape, note_target.shape)\n",
    "print(train.min(),train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18439, 168, 87, 1) (2049, 168, 87, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    train, target, test_size=0.1, stratify=target\n",
    ")\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_net_model(input_tensor):\n",
    "# U-net모델 만들기\n",
    "## tools\n",
    "    conv_filters = [16, 32, 64, 128, 256, 512]\n",
    "    cont_factory = partial(\n",
    "        keras.layers.Cont, kernel_size=(3,3), strides=1, padding=\"same\"\n",
    "    )\n",
    "    cont_activation = keras.layers.ELU()\n",
    "    \n",
    "    expan_factory = partial(\n",
    "        keras.layers.Conv2DTranspose,\n",
    "        kernel_size=(3,3), strides=1, padding=\"same\"\n",
    "    )\n",
    "    expan_activation = keras.layers.LeakyReLU(0.2)\n",
    "\n",
    "## Contracting path\n",
    "    ## 1\n",
    "    conv1 = cont_factory(conv_filters[0])(input_tensor)\n",
    "    batch1 = keras.layers.BatchNormalization(axis=-1)(conv1)\n",
    "    rel1 = cont_activation(batch1)\n",
    "    ## 2\n",
    "    conv2 = cont_factory(conv_filters[1])(rel1)\n",
    "    batch2 = keras.layers.BatchNormalization(axis=-1)(conv2)\n",
    "    rel2 = cont_activation(batch2)\n",
    "    ## 3\n",
    "    conv3 = cont_factory(conv_filters[2])(rel2)\n",
    "    batch3 = keras.layers.BatchNormalization(axis=-1)(conv3)\n",
    "    rel3 = cont_activation(batch3)\n",
    "    ## 4\n",
    "    conv4 = cont_factory(conv_filters[3])(rel3)\n",
    "    batch4 = keras.layers.BatchNormalization(axis=-1)(conv4)\n",
    "    rel4 = cont_activation(batch4)\n",
    "    ## 5\n",
    "    conv5 = cont_factory(conv_filters[4])(rel4)\n",
    "    batch5 = keras.layers.BatchNormalization(axis=-1)(conv5)\n",
    "    rel5 = cont_activation(batch5)\n",
    "    ## 6\n",
    "    conv6 = cont_factory(conv_filters[5])(rel5)\n",
    "\n",
    "## Expansive path\n",
    "    ## 6\n",
    "    up1 = expan_factory(conv_filters[4])(conv6)\n",
    "    up1 = expan_activation(up1)\n",
    "    up_batch1 = keras.layers.BatchNormalization(axis=-1)(up1)\n",
    "    drop1 = keras.layers.Dropout(0.5)(up_batch1)\n",
    "    merge1 = keras.layers.Concatenate(axis=-1)([conv5,drop1])\n",
    "    ## 5\n",
    "    up2 = expan_factory(conv_filters[3])(merge1)\n",
    "    up2 = expan_activation(up2)\n",
    "    up_batch2 = keras.layers.BatchNormalization(axis=-1)(up2)\n",
    "    drop2 = keras.layers.Dropout(0.5)(up_batch2)\n",
    "    merge2 = keras.layers.Concatenate(axis=-1)([conv4,drop2])\n",
    "    ## 4\n",
    "    up3 = expan_factory(conv_filters[2])(merge2)\n",
    "    up3 = expan_activation(up3)\n",
    "    up_batch3 = keras.layers.BatchNormalization(axis=-1)(up3)\n",
    "    drop3 = keras.layers.Dropout(0.5)(up_batch3)\n",
    "    merge3 = keras.layers.Concatenate(axis=-1)([conv3,drop3])\n",
    "    ## 3\n",
    "    up4 = expan_factory(conv_filters[1])(merge3)\n",
    "    up4 = expan_activation(up4)\n",
    "    up_batch4 = keras.layers.BatchNormalization(axis=-1)(up4)\n",
    "    drop4 = keras.layers.Dropout(0.5)(up_batch4)\n",
    "    merge4 = keras.layers.Concatenate(axis=-1)([conv2,drop4])\n",
    "    ## 2\n",
    "    up5 = expan_factory(conv_filters[0])(merge4)\n",
    "    up5 = expan_activation(up5)\n",
    "    up_batch5 = keras.layers.BatchNormalization(axis=-1)(up5)\n",
    "    drop5 = keras.layers.Dropout(0.5)(up_batch5)\n",
    "    merge5 = keras.layers.Concatenate(axis=-1)([conv1,drop5])\n",
    "    ## 1\n",
    "    up6 = expan_factory(1)(merge5)\n",
    "    up6 = expan_activation(up6)\n",
    "    up_batch6 = keras.layers.BatchNormalization(axis=-1)(up6)\n",
    "## output\n",
    "    return keras.layers.Conv2D(2, (4,4), dilation_rate=(2,2), activation=\"sigmoid\", padding=\"same\")(up_batch6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7ceefec71f59fb0985b7b98aa0f9117e630e2565b77be81cab4e2a12c0fe131"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
